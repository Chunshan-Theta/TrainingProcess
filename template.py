# -*- coding: utf-8 -*-
"""CKIP-Bert [MBTI]的副本

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I6s7nRg_J76aBFMa2V-RRpJEcLRF4Xjr

# 環境建置

環境變數
"""

env = {
    "max_seq_length": 64
}

# !pip install sentence-transformers==2.1.0
# !pip install torch==1.9.0
# !pip install transformers==3
!pip install torch>=1.9.0
# !pip install sentence-transformers==2.1.0
!pip install jieba
# !pip install transformers==4.11.3
!pip install transformers
!pip  install datasets
#
!pip install PyYAML
!pip install hanziconv
!pip install pypinyin
!pip install pandas
!pip install ruamel.yaml

import torch

# If there's a GPU available...
if torch.cuda.is_available():    

    # Tell PyTorch to use the GPU.    
    device = torch.device("cuda")

    print('There are %d GPU(s) available.' % torch.cuda.device_count())

    print('We will use the GPU:', torch.cuda.get_device_name(0))

# If not...
else:
    print('No GPU available, using the CPU instead.')
    device = torch.device("cpu")

"""#下載資料

"""

# 下載訓練資料
# Data Lake in Drive
# https://drive.google.com/file/d/1MJKmJJsOHnHM-VjbNZ3nDoCK9WxsTrU9/view?usp=sharing
import requests

def download_file_from_google_drive(id, destination):
    URL = "https://docs.google.com/uc?export=download"

    session = requests.Session()

    response = session.get(URL, params = { 'id' : id }, stream = True)
    token = get_confirm_token(response)

    if token:
        params = { 'id' : id, 'confirm' : token }
        response = session.get(URL, params = params, stream = True)

    save_response_content(response, destination)    

def get_confirm_token(response):
    for key, value in response.cookies.items():
        if key.startswith('download_warning'):
            return value

    return None

def save_response_content(response, destination):
    CHUNK_SIZE = 32768

    with open(destination, "wb") as f:
        for chunk in response.iter_content(CHUNK_SIZE):
            if chunk: # filter out keep-alive new chunks
                f.write(chunk)

if __name__ == "__main__":
    file_id = "<gdrive-id>"
    destination = './source.txt'
    download_file_from_google_drive(file_id, destination)

"""# 設定資料定義
https://csc.nutc.edu.tw/ezfiles/34/1034/img/1292/175552181.pdf


| 大分類 | 個人解釋 | 小分類 | 代號 | 個人解釋 |
| --- | --- | --- | --- | --- |
| 泛指一個人發洩及獲得心靈能量的方向。 | 舒適圈的位置 | 外向 | E | 著重專注在關於社群發展、組織變動、人際關係 |
| 泛指一個人發洩及獲得心靈能量的方向。 | 舒適圈的位置 | 內向 | I | 著重專注在關於自我成長、思考探討、個人活動 |
| 泛指人們認識世界、處理資訊的方法。 | 思考與記憶的方式 | 實感 | S | 根據 數據/細節/資料 進行思考 |
| 泛指人們認識世界、處理資訊的方法。 | 思考與記憶的方式 | 直覺 | N | 根據 概念/經驗/印象 進行思考 |
| 下決定時內心掙扎所側重的方向 | 決策的關鍵 | 情感 | F | 根據 情感/喜好/認知 做決定 |
| 下決定時內心掙扎所側重的方向 | 決策的關鍵 | 思考 | T | 根據 數據/邏輯/估值 做決定 |
| 世界觀及生活模式 | 對於未來的規劃 | 判斷 | J | 方針著重在 降低風險、擅於計畫 |
| 世界觀及生活模式 | 對於未來的規劃 | 感知 | P | 方針著重在 挑戰風險、掌握機會 |
"""

document ="""
config:
    - type: nlu
    - label: mbti


intents:
    - intent1: 
      - entities-E:
        - 同事,上司,主管,老闆,朋友,同學,夥伴,(其他|其它)+.*(人|員工)+
        - 找不到人問,怎麼回答,(暗自|私底下|私下)+.*(找|和|與|叫|喊)+.*(溝通|協調|合作)+
        - (一起|大家)+.*(溝通|協調|合作|上班|下班|聊天|吃飯|休息|喝水|裝水)+
        - 珠寶,手飾,補教業,人事,任用,招募,生涯
        - 行銷,電話,客戶,他們,錄取,人資,員工,管理,加班,部門,人員,助理,朋友,新人,老闆
      
      
      - entities-I:
        - 成長,學習,閱讀,技能,向上,思考,個人
        - 自己來,份內,干擾,隱私,私事,埋頭,鑽牛角尖,專注,不自在,沉默,精進,致力,自我要求,自責,自認,本身,給自己,想清楚,內傷,想通
        - (朝|向)+.*(方面|未來|方向|規劃|計畫)+.*(努力|學習|成長|調整)+
        - 積極,應徵,機構,念書,主修,國考,穩定,朝九晚五,留學,升遷
        - 會計,分析,資料,導體,半導體,接觸,負責,產品,實習,設備,事務所,專案,現職,身體,加班,科技業,自己個性,自己單位
        - (自己|我|自身)+.*(個性|性格|習慣|經驗|能力)+



    - intent2: 
      - entities-N:
        - 概念,經驗,印象,以前,曾經
        - 剛好,期間,終於,積極,專心,焦慮,萬一,印象,玻璃心,朝九晚五,出國,留學
        - 一邊,總是,結果,外商,喜歡,願意,當時,實際
        
        - 總覺得,似乎,算是,一想到,不知不覺,很怕之後,難道,大方向,感受到,好像都,難道,大方向,感受到
        - 一想到,不知不覺,很怕.*之後
        - (好像|似乎|大部分|幾乎)+.*(都|全部)+
        - 有.*(感覺|感受)+

      - entities-S:
        - 數據,機率,可能性,推估,業績,金額
        - 偏向,因此,連結,薪資,績效,賺點
        - 資料,分析,研究,業績
        
        - 何必,尤其,看來,觀察,基於,舉例,後發現,一步一步,合理,再加上



    - intent3: 
      - entities-T:
        - 思考,數據,機率,可能性,推估,估計,業績,成果,成績,學歷,經歷,學校
        - 苦尋,任期,正在,方面,爭取,很想,再次,計算,給予,常性,查詢,工資,許多,勞動,固定,平均,合同,執行,作業,列為,必須,納入,獎金,績效,營收,工資,歷年,這樣,工資,算進,我查,絕對,說法,法務,倒底,判例,恩惠,困惑,解答,法令,比如
        - 助理,遊戲,薪資,設計,工地,管理,也是,同事,內容,履歷,老闆,工程師,退伍,建築,主管,操作,現場,行銷,代理,轉職,未來,如果,學歷,無法,人員,後來,喜歡,一年,問題,是否,發展,可能,最近,時間,什麼,對於,研發,編輯,公職,化學,遇到,這樣,但是,領域,找到,每天,工程

        - 可行,看好,有助於,角度,做打算,長久之計,頂多,偏向於
        - 前途,生涯
        - (比較|相較)+.*有機會


      - entities-F:
        - 感覺,感受,積極,向上,徬徨,積極,動力,喜歡,習慣,興趣,喜好,熱情
        - 近且,鮮少,念書,主修,研究所,符合,考國考,國考,改兼職,壞處,玻璃心,出國,留學,逐漸,動力,有升遷,經無法,週一到,還選擇,台灣會,外派,玩命,回去,還沒,回台灣,口罩,一堆,疫苗,拿命,愛怎樣,確診,聽膩,無感,在連,接種,擠地,超像,之戰,旁邊,不戴,超近,連結,從頭,戴滿,賺點,問現,我調,在衝,再撐
        - 一邊,會計,客戶,英文,採購,護理,加班,維修,美髮,食品,分析,資料,電話,事務,程式,開發,新人,業績,協助,銀行,下班,實習,設備,經理,有時,工廠,門市,事務所,員工,一天,活動,小孩,金融,離開,產品,研究,研發,後來,請假,行銷,媒體,診所,感謝,思考,能夠,一次,決定,不過,私立,起來
        
        - 心軟,人情,面子,同情,心累,共識,吞下去,的立場,罪惡感,有意義
        - 硬著頭皮.*(答應|完成|成交)+


    - intent4: 
      - entities-J:
        - 安全,放棄,如期,備案,穩定,長久之計,做打算,想清楚,不確定性,養活,以防,以防萬一,妥善,後路
        - (有|曾).*(想過|計畫|規劃|打算)+.*(但|可是)+,(讓|使)+.*(安心|放心)+
        - (比較|相對|會更|更加).*(保險|保障|風險|危險)+.*


      - entities-P:
        - 試試,枯燥,直接去,偷偷,放空,挑戰性,眼界,放手一搏,心動,就來不及,趁,死腦筋,無趣,無聊,呆板,耍廢,新鮮感,見見世面,看看,衝一波,放手一試
        - (不放過|不錯過)+.*(機會|可能性)+,避免.*遺憾,(能|可以|將會)+.*(學到|了解)+,(萌生|產生)+.*(念頭|想法)+
        - (換|改變|跳|轉).*(跑道|工作|機會|職位|領域|未來)+.*


"""

import yaml
from ruamel.yaml import YAML
from ruamel.yaml.reader import Reader

def strip_invalid(s):
    res = ''
    for x in s:
        if Reader.NON_PRINTABLE.match(x):
            # res += '\\x{:x}'.format(ord(x))
            continue
        res += x
    return res

try:
    obj = yaml.safe_load(strip_invalid(document))
except yaml.YAMLError as e:
    print("Parsing YAML string failed")
    print("Reason:", e.reason)
    print("At position: {0} with encoding {1}".format(e.position, e.encoding))
    print("Invalid char code:", e.character)
    raise e


intents = obj["intents"]

"""# 產生資料

"""

max_seq_length = env['max_seq_length']

import re
def keep_zh(text):
    return re.sub(r'[^\u4e00-\u9fa5]','',text)

from typing import List
def substrings(long_string: str, max_len: int) -> List[str]:
  if len(long_string) <= max_len:
    return [long_string]
  len_long_string: int  = len(long_string)
  return_arr: List[str] = []
  group_num: int  = len_long_string // max_len
  output_sent_len: int =  int(len_long_string/group_num) if (len_long_string/group_num) <= max_len else max_len
  bias: int  = len_long_string - output_sent_len*group_num +1
  print()
  for turn in range(group_num):
    return_arr.append(long_string[bias*turn: bias*turn+output_sent_len])
  return return_arr

substrings("背景私立大學畢多益約分持續進修英文口說和商業軟體無會計師執照四大事務所年上市櫃電子製造業年現職預計報名碩士在職專班希望未來能有穩定工作和一定的競爭力目前公司產業屬於電子傳產本身都有調薪只是獲利不穩導致分紅較差職務內容主係負責合併報表跟成本會計除了份內工作外也會請教其他同事負責的普會工作內容並學習操作跟流程但由於規模現職公司雖是上市櫃但營收跟科技大廠比起來還是相對很小以及工作風氣關係處理上都以簡單為主並無太深也沒有特殊專案學習有限害怕沒有成長未來越來越沒競爭力因此想趁年紀還沒有很大時考量轉換到更大的公司學習一方面是大公司穩定度跟學習較好再來不管之後是否還會再轉換工作大公司的經歷加分效果仍是較大希望能夠在大型公司營收破百億負責經營分析的職務但不知道根據我的學經歷這樣的想法對發展職涯競爭力是否正確應該跳到規模更大的公司還是先留在原職就好如果留在原職主管告知預計安排後年外派中國廠當財務小主管外派時間大約年因外派時間較長的關係進修計畫需被迫調整而且不確定外派這段時間公司會發生甚麼變化公司目前所處市場競爭越來越激烈獲利程度跟以往相比也減少許多以及這次外派其實是部門首次有人外派整個公司也是近十年沒有外派過人所以外派的各項福利都尚未有很明確規範想問說是否該接受外派這樣的外派工作經驗對於本身發展是否有加分效果假設外派結束回來如被迫需要轉換工作累積的外派經驗是否有可能被其他公司不重視導致受年紀太大和經歷不佳影響無法在人力市場上有競爭力", 128)

rows= []
with open("source.txt") as source_data:
    for row in source_data.readlines():
      rows.append(row.strip("\n"))

rows = [keep_zh(row) for row in set(rows) if len(row) > 5]

#
rowdata = []
for row in rows:
  for sent in substrings(row, max_seq_length):
    rowdata.append(sent)

rows[:25]

rowdata[:25]

import re

#
train_rows = {} 
label_idxs = []
def listRightIndex(alist, value):
    return len(alist) - alist[-1::-1].index(value) -1

def pattenSent(s,p):
  regex = re.compile(p)
  return False if regex.search(s) is None else True

for intent in intents:
  for label_name, unit_intent in intent.items():
    label_idxs.append(label_name)
    score_list = []
    entities_positive = []
    for entity in list(unit_intent[0].values())[0]:
      entities_positive.extend(entity.split(","))
    entities_positive = list(set(entities_positive))


    entities_negitive = []
    for entity in list(unit_intent[1].values())[0]:
      entities_negitive.extend(entity.split(","))
    entities_negitive = list(set(entities_negitive))

    

    for sentecne in rowdata:
      sentecne_score = 0
      for p_word in entities_positive:
        if pattenSent(sentecne,p_word):
          sentecne_score+=1

      for n_word in entities_negitive:
        if pattenSent(sentecne,n_word):
          sentecne_score-=1

      score_list.append(sentecne_score)
    score_list.sort()
    print(f"entities_positive: {entities_positive}")
    print(f"entities_negitive: {entities_negitive}")



    for sentecne in rowdata:
      sentecne_score = 0
      for p_word in entities_positive:
        if pattenSent(sentecne,p_word):
          sentecne_score+=1

      for n_word in entities_negitive:
        if pattenSent(sentecne,n_word):
          sentecne_score-=1
      
      
      left_point = score_list.index(sentecne_score)
      right_point = listRightIndex(score_list, sentecne_score)
      center_point = (left_point+right_point)/2
      sentecne_score = round(center_point/len(score_list),0)


      if sentecne not in train_rows:
        train_rows[sentecne] = []
      train_rows[sentecne].append(sentecne_score)
train_rows =[[scores,sentence] for sentence, scores in train_rows.items() if len(scores) == 4]

len(train_rows)

train_rows

"""# 資料前處理

### 設定預模型
"""

# bert_model = "ckiplab/albert-tiny-chinese"
# bert_model = "bert-base-chinese"
# bert_model = "ckiplab/bert-base-chinese"
bert_model = "hfl/chinese-roberta-wwm-ext"
# bert_model = "hfl/chinese-bert-wwm-ext"

max_seq_length = env['max_seq_length']


from transformers import BertTokenizer,BertTokenizerFast
# tokenizer = BertTokenizer.from_pretrained(bert_model)
tokenizer = BertTokenizerFast.from_pretrained(bert_model)

"""### 設定資料集"""

# Importing stock ml libraries
import numpy as np
import pandas as pd
from sklearn import metrics
from sklearn.model_selection import train_test_split

import transformers
import torch
from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler
from transformers import BertTokenizer, BertModel, BertConfig

class CustomDataset(Dataset):

    def __init__(self, dataframe, tokenizer, max_len):
        self.tokenizer = tokenizer
        self.data = dataframe
        self.title = dataframe[1]
        self.targets = dataframe[0]
        self.max_len = max_len

    def __len__(self):
        return len(self.title)

    def __getitem__(self, index):
        title = str(self.title[index])
        title = " ".join(title.split())

        inputs = self.tokenizer.encode_plus(
            title,
            None,
            add_special_tokens=True,
            max_length=self.max_len,
            padding='max_length',
            return_token_type_ids=True,
            truncation=True
        )
        ids = inputs['input_ids']
        mask = inputs['attention_mask']
        token_type_ids = inputs["token_type_ids"]


        return {
            'input_ids': torch.tensor(ids, dtype=torch.long),
            'attention_mask': torch.tensor(mask, dtype=torch.long),
            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),
            'labels': torch.tensor(self.targets[index], dtype=torch.float)
        }
    
    def samples(self):
      return [(title[:self.max_len], target) for target,title in zip(self.targets, self.title)]

train_rows

numpy_data = np.array(train_rows)
numpy_data = pd.DataFrame(data=numpy_data)
# numpy_data = numpy_data.sample(int(len(numpy_data)))

numpy_data

from sklearn.model_selection import train_test_split
trainset, testset = train_test_split(numpy_data, test_size=0.1, random_state = 2022)
trainset, testset = trainset.reset_index(), testset.reset_index()

testset

#
training_set = CustomDataset(trainset, tokenizer, max_seq_length)
validation_set = CustomDataset(testset, tokenizer, max_seq_length)

"""# Model

## training tool

### PIPELINE Define
"""

import numpy as np
from transformers import Pipeline
from transformers.utils import ExplicitEnum, add_end_docstrings, is_tf_available, is_torch_available
from typing import Union, List, Dict
if is_tf_available():
    from transformers.models.auto.modeling_tf_auto import TF_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING
if is_torch_available():
    from transformers.models.auto.modeling_auto import MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING


GenericTensor = Union[List["GenericTensor"], "torch.Tensor", "tf.Tensor"]

class ClassificationFunction(ExplicitEnum):
    SIGMOID = "sigmoid"
    SOFTMAX = "softmax"
    NONE = "none"

def sigmoid(_outputs):
    return 1.0 / (1.0 + np.exp(-_outputs))

def softmax(_outputs):
    maxes = np.max(_outputs, axis=-1, keepdims=True)
    shifted_exp = np.exp(_outputs - maxes)
    return shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)

class MultiClassificationPipeline(Pipeline):
    """
    Text classification pipeline using any `ModelForSequenceClassification`. See the [sequence classification
    examples](../task_summary#sequence-classification) for more information.
    This text classification pipeline can currently be loaded from [`pipeline`] using the following task identifier:
    `"sentiment-analysis"` (for classifying sequences according to positive or negative sentiments).
    If multiple classification labels are available (`model.config.num_labels >= 2`), the pipeline will run a softmax
    over the results. If there is a single label, the pipeline will run a sigmoid over the result.
    The models that this pipeline can use are models that have been fine-tuned on a sequence classification task. See
    the up-to-date list of available models on
    [huggingface.co/models](https://huggingface.co/models?filter=text-classification).
    """

    return_all_scores = False
    function_to_apply = ClassificationFunction.NONE

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        self.check_model_type(
            TF_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING
            if self.framework == "tf"
            else MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING
        )

        self.tokenizer_inputs = None
    def keep_zh(self, text):
      return re.sub(r'[^\u4e00-\u9fa5]','',text)
    def _sanitize_parameters(self, return_all_scores=None, function_to_apply=None, **tokenizer_kwargs):
        preprocess_params = tokenizer_kwargs

        postprocess_params = {}
        if hasattr(self.model.config, "return_all_scores") and return_all_scores is None:
            return_all_scores = self.model.config.return_all_scores

        if return_all_scores is not None:
            postprocess_params["return_all_scores"] = return_all_scores

        if isinstance(function_to_apply, str):
            function_to_apply = ClassificationFunction[function_to_apply.upper()]

        if function_to_apply is not None:
            postprocess_params["function_to_apply"] = function_to_apply
        return preprocess_params, {}, postprocess_params

    def __call__(self, *args, **kwargs):
        """
        Classify the text(s) given as inputs.
        Args:
            args (`str` or `List[str]`):
                One or several texts (or one list of prompts) to classify.
            return_all_scores (`bool`, *optional*, defaults to `False`):
                Whether to return scores for all labels.
            function_to_apply (`str`, *optional*, defaults to `"default"`):
                The function to apply to the model outputs in order to retrieve the scores. Accepts four different
                values:
                If this argument is not specified, then it will apply the following functions according to the number
                of labels:
                - If the model has a single label, will apply the sigmoid function on the output.
                - If the model has several labels, will apply the softmax function on the output.
                Possible values are:
                - `"sigmoid"`: Applies the sigmoid function on the output.
                - `"softmax"`: Applies the softmax function on the output.
                - `"none"`: Does not apply any function on the output.
        Return:
            A list or a list of list of `dict`: Each result comes as list of dictionaries with the following keys:
            - **label** (`str`) -- The label predicted.
            - **score** (`float`) -- The corresponding probability.
            If `self.return_all_scores=True`, one such dictionary is returned per label.
        """
        result = super().__call__(*args, **kwargs)
        if isinstance(args[0], str):
            # This pipeline is odd, and return a list when single item is run
            return [result]
        else:
            return result

    def preprocess(self, inputs, **tokenizer_kwargs) -> Dict[str, GenericTensor]:
        # print(inputs)
        inputs = self.keep_zh(inputs)
        return_tensors = self.framework
        tokenizer_inputs = self.tokenizer(inputs, return_tensors=return_tensors, **tokenizer_kwargs)
        self.tokenizer_inputs = self.tokenizer.convert_ids_to_tokens(tokenizer_inputs['input_ids'][0])
        return tokenizer_inputs

    def _forward(self, model_inputs):
        result = self.model(**model_inputs)
        return result

    def postprocess(self, model_outputs, function_to_apply=None, return_all_scores=False):
        # Default value before `set_parameters`
        if function_to_apply is None:
            if self.model.config.problem_type == "multi_label_classification" or self.model.config.num_labels == 1:
                function_to_apply = ClassificationFunction.SIGMOID
            elif self.model.config.problem_type == "single_label_classification" or self.model.config.num_labels > 1:
                function_to_apply = ClassificationFunction.SOFTMAX
            elif hasattr(self.model.config, "function_to_apply") and function_to_apply is None:
                function_to_apply = self.model.config.function_to_apply
            else:
                function_to_apply = ClassificationFunction.NONE

        outputs = model_outputs["logits"][0]
        attention = self.attention2value(model_outputs["attentions"])
        outputs = outputs.numpy()

        if function_to_apply == ClassificationFunction.SIGMOID:
            scores = sigmoid(outputs)
        elif function_to_apply == ClassificationFunction.SOFTMAX:
            scores = softmax(outputs)
        elif function_to_apply == ClassificationFunction.NONE:
            scores = outputs
        else:
            raise ValueError(f"Unrecognized `function_to_apply` argument: {function_to_apply}")

        if return_all_scores:
            return {
                "labels": [{"label": self.model.config.id2label[i], "score": score.item()} for i, score in enumerate(scores)],
                "content": self.tokenizer_inputs,
                "attention": attention,
                "length":len(self.tokenizer_inputs)
            }
            
        else:
            return [score.item() for i, score in enumerate(scores)]

    def attention2value(self, attention):
        def level_attention_value(arr_2d):
          attention_base = arr_2d[0].numpy()
          for unit in arr_2d[1:]:
            attention_base+=unit.numpy()
          return attention_base
        attention_base, level_count = np.array([0.0]*len(self.tokenizer_inputs)), 0
        for level1 in attention:
          for level2 in level1[0]:
            level_count+=1
            attention_base += level_attention_value(level2)
        return attention_base/level_count

"""### validation data process

"""

from typing import List
def get_validation_set() -> List[float]:
  return validation_set.samples()
get_validation_set()

"""### acc tool"""

from sklearn.metrics import multilabel_confusion_matrix as mcm, classification_report

from typing import List
def get_score(cm: np.ndarray) -> List[int]:
  return_arr: List[int] = []
  
  for i in range(0,4):
    top = cm[i][0][0]+cm[i][1][1]
    bottom = cm[i][0][1]+cm[i][1][0]+1
    # print(f"{top} / {bottom}= {top/bottom}")
    return_arr.append(top/bottom)

  return return_arr

cm = mcm([[1, 1, 0, 0]], [[1, 1, 0, 1]])
# cm = mcm(val_targs, val_preds)
get_score(cm)

def get_preds(m, t):
  o = [ans for text,ans in get_validation_set()]
  d = [text for text,ans in get_validation_set()]
  PipelineInterface = MultiClassificationPipeline(model=m, tokenizer=t, return_all_scores=True)
  validation_set_sample_report = [PipelineInterface(sd)[0] for sd in d]
  val_outputs = [r for r in validation_set_sample_report]
  return o, d

from sklearn.metrics import multilabel_confusion_matrix as mcm, classification_report


def get_best_th(val_outputs: List[List[float]], val_targets: List[List[float]], show_dashboard: bool =False) -> List[float]:
  #
  best_threshold = 0.5
  best_score = 0.001
  best_report = None
  for th in [ i/1000 for i in range(1,1000,10)]:
    #
    val_preds = (np.array(val_outputs) > th).astype(int)
    val_targs = (np.array(val_targets) > 0.5).astype(int)

    cm = mcm(val_targs, val_preds)
    score = sum(get_score(cm))/4
    if score > best_score:
      best_threshold = th
      best_report = classification_report(val_targs, val_preds)
      best_score = score
  if show_dashboard:
    print(best_threshold)
    print(best_report)

  return [best_score, best_threshold]

"""## setup the model"""

from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer




model = AutoModelForSequenceClassification.from_pretrained(
    bert_model, 
    num_labels=4,
    id2label={
      0: 'E/I', 1: 'N/S', 2: 'T/F', 3: 'J/P'    
    }
)
model.config.hidden_dropout_prob = 0.3
model.config.attention_probs_dropout_prob = 0.05

model.config

from transformers import DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

from datasets import load_metric
metric = load_metric('accuracy')

def compute_metrics(eval_pred):

  predictions, labels = eval_pred.predictions, eval_pred.label_ids
  # print(f"predictions: {predictions}")
  # print(f"labels: {labels}")
  val_preds = (np.array(predictions) > 0.5).astype(int)
  val_targs = (np.array(labels) > 0.5).astype(int)
  # print(f"val_preds: {val_preds}")
  # print(f"val_targs: {val_targs}")
  val_preds = np.argmax(val_preds, axis=1)
  val_targs = np.argmax(val_targs, axis=1)
  return metric.compute(predictions=val_preds, references=val_targs)

"""### Train point"""

training_args = TrainingArguments(
    output_dir="./results",
    learning_rate=1e-5,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=32,
    num_train_epochs=15,
    warmup_steps=300,
    weight_decay=0,
    logging_steps=10,
    save_steps=100,
    seed=42,
    data_seed=2022,
    evaluation_strategy="steps",
    eval_steps=10,
    load_best_model_at_end=True,
    save_total_limit=3

)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=training_set,
    eval_dataset=validation_set,
    tokenizer=tokenizer,
    # data_collator=data_collator, 
    # callbacks=[DetailCallback]
    compute_metrics=compute_metrics
)

train = trainer.train()

"""# 預測"""

from transformers import AutoModelForSequenceClassification
new_model = AutoModelForSequenceClassification.from_pretrained("./results/checkpoint-3200/",output_attentions=True)

PipelineInterface = MultiClassificationPipeline(model=new_model, tokenizer=tokenizer, return_all_scores=False)
PipelineInterface("同理心很重要")

"""# Report Summary"""



import datetime

validation_set_sample = validation_set.samples()

val_outputs = []
count = len(validation_set)
print(f"count:{count}")
idx = 0
s = datetime.datetime.now()
validation_set_sample_report = [PipelineInterface(text)[0] for text, ans in validation_set_sample]
print(f"總時間: {(datetime.datetime.now() - s).seconds}")
print(f"總時間: {(datetime.datetime.now() - s).seconds/count}")

val_outputs=[]
for results in validation_set_sample_report:
  #
  val_outputs.append(results)

#
val_targets = [ans for text,ans in get_validation_set()]

from sklearn.metrics import multilabel_confusion_matrix as mcm, classification_report

#
best_threshold = 0.5
best_score = 0.001
best_report = None
for th in [ i/1000 for i in range(1,1000,10)]:
  #
  val_preds = (np.array(val_outputs) > th).astype(int)
  val_targs = (np.array(val_targets) > 0.5).astype(int)

  cm = mcm(val_targs, val_preds)
  score = sum(get_score(cm))/4
  if score > best_score:
    best_threshold = th
    best_report = classification_report(val_targs, val_preds)
    best_score = score

print(best_threshold)
print(best_report)

"""###### output"""

texts = [text for text in testset[1]]
with open("output.csv","w") as f,open("output1.csv","w") as f1,open("output2.csv","w") as f2,open("output3.csv","w") as f3,open("output4.csv","w") as f4:
    f.write(f"答案標籤\t模型預測標籤\t答案分數\t模型預測分數\t內容\n")
    f1.write(f"答案標籤\t模型預測標籤\t答案分數\t模型預測分數\t內容\n")
    f2.write(f"答案標籤\t模型預測標籤\t答案分數\t模型預測分數\t內容\n")
    f3.write(f"答案標籤\t模型預測標籤\t答案分數\t模型預測分數\t內容\n")
    f4.write(f"答案標籤\t模型預測標籤\t答案分數\t模型預測分數\t內容\n")
    for text,model_result,ans_result,model_res_tag,ans_res_tag  in zip(texts,val_outputs,val_targets,val_preds,val_targs):
      model_result = [round(v,3) for v in model_result]

      #
      f.write(f"{ans_res_tag}\t{model_res_tag}\t{ans_result}\t{model_result}\t{text}\n")
      f1.write(f"{ans_res_tag[0]}\t{model_res_tag[0]}\t{ans_result[0]}\t{model_result[0]}\t{text}\n")
      f2.write(f"{ans_res_tag[1]}\t{model_res_tag[1]}\t{ans_result[1]}\t{model_result[1]}\t{text}\n")
      f3.write(f"{ans_res_tag[2]}\t{model_res_tag[2]}\t{ans_result[2]}\t{model_result[2]}\t{text}\n")
      f4.write(f"{ans_res_tag[3]}\t{model_res_tag[3]}\t{ans_result[3]}\t{model_result[3]}\t{text}\n")

"""# 下方手動區 停止"""

stop

"""###### 模型 v4



```
              precision    recall  f1-score   support

           0       0.78      0.66      0.71       296
           1       0.74      0.71      0.73       272
           2       0.70      0.72      0.71       272
           3       0.78      0.69      0.73       316

   micro avg       0.75      0.69      0.72      1156
   macro avg       0.75      0.69      0.72      1156
weighted avg       0.75      0.69      0.72      1156
 samples avg       0.73      0.68      0.68      1156
 ```


"""

document ="""
config:
    - type: nlu
    - label: mbti


intents:
    - intent1: 
      - entities-E:
        - 同事,上司,主管,老闆,朋友,同學,夥伴,(其他|其它)+.*(人|員工)+
        - 找不到人問,怎麼回答,(暗自|私底下|私下)+.*(找|和|與|叫|喊)+.*(溝通|協調|合作)+
        - (一起|大家)+.*(溝通|協調|合作|上班|下班|聊天|吃飯|休息|喝水|裝水)+
        - 珠寶,手飾,補教業,人事,任用,招募,生涯
        - 行銷,電話,客戶,他們,錄取,人資,員工,管理,加班,部門,人員,助理,朋友,新人,老闆
      
      
      - entities-I:
        - 成長,學習,閱讀,技能,向上,思考,個人
        - 自己來,份內,干擾,隱私,私事,埋頭,鑽牛角尖,專注,不自在,沉默,精進,致力,自我要求,自責,自認,本身,給自己,想清楚,內傷,想通
        - (朝|向)+.*(方面|未來|方向|規劃|計畫)+.*(努力|學習|成長|調整)+
        - 積極,應徵,機構,念書,主修,國考,穩定,朝九晚五,留學,升遷
        - 會計,分析,資料,導體,半導體,接觸,負責,產品,實習,設備,事務所,專案,現職,身體,加班,科技業,自己個性,自己單位
        - (自己|我|自身)+.*(個性|性格|習慣|經驗|能力)+



    - intent2: 
      - entities-N:
        - 概念,經驗,印象,以前,曾經
        - 剛好,期間,終於,積極,專心,焦慮,萬一,印象,玻璃心,朝九晚五,出國,留學
        - 一邊,總是,結果,外商,喜歡,願意,當時,實際
        
        - 總覺得,似乎,算是,一想到,不知不覺,很怕之後,難道,大方向,感受到,好像都,難道,大方向,感受到
        - 一想到,不知不覺,很怕.*之後
        - (好像|似乎|大部分|幾乎)+.*(都|全部)+
        - 有.*(感覺|感受)+

      - entities-S:
        - 數據,機率,可能性,推估,業績,金額
        - 偏向,因此,連結,薪資,績效,賺點
        - 資料,分析,研究,業績
        
        - 何必,尤其,看來,觀察,基於,舉例,後發現,一步一步,合理,再加上



    - intent3: 
      - entities-T:
        - 思考,數據,機率,可能性,推估,估計,業績,成果,成績,學歷,經歷,學校
        - 苦尋,任期,正在,方面,爭取,很想,再次,計算,給予,常性,查詢,工資,許多,勞動,固定,平均,合同,執行,作業,列為,必須,納入,獎金,績效,營收,工資,歷年,這樣,工資,算進,我查,絕對,說法,法務,倒底,判例,恩惠,困惑,解答,法令,比如
        - 助理,遊戲,薪資,設計,工地,管理,也是,同事,內容,履歷,老闆,工程師,退伍,建築,主管,操作,現場,行銷,代理,轉職,未來,如果,學歷,無法,人員,後來,喜歡,一年,問題,是否,發展,可能,最近,時間,什麼,對於,研發,編輯,公職,化學,遇到,這樣,但是,領域,找到,每天,工程

        - 可行,看好,有助於,角度,做打算,長久之計,頂多,偏向於
        - 前途,生涯
        - (比較|相較)+.*有機會


      - entities-F:
        - 感覺,感受,積極,向上,徬徨,積極,動力,喜歡,習慣,興趣,喜好,熱情
        - 近且,鮮少,念書,主修,研究所,符合,考國考,國考,改兼職,壞處,玻璃心,出國,留學,逐漸,動力,有升遷,經無法,週一到,還選擇,台灣會,外派,玩命,回去,還沒,回台灣,口罩,一堆,疫苗,拿命,愛怎樣,確診,聽膩,無感,在連,接種,擠地,超像,之戰,旁邊,不戴,超近,連結,從頭,戴滿,賺點,問現,我調,在衝,再撐
        - 一邊,會計,客戶,英文,採購,護理,加班,維修,美髮,食品,分析,資料,電話,事務,程式,開發,新人,業績,協助,銀行,下班,實習,設備,經理,有時,工廠,門市,事務所,員工,一天,活動,小孩,金融,離開,產品,研究,研發,後來,請假,行銷,媒體,診所,感謝,思考,能夠,一次,決定,不過,私立,起來
        
        - 心軟,人情,面子,同情,心累,共識,吞下去,的立場,罪惡感,有意義
        - 硬著頭皮.*(答應|完成|成交)+


    - intent4: 
      - entities-J:
        - 安全,放棄,如期,備案,穩定,長久之計,做打算,想清楚,不確定性,養活,以防,以防萬一,妥善,後路
        - (有|曾).*(想過|計畫|規劃|打算)+.*(但|可是)+,(讓|使)+.*(安心|放心)+
        - (比較|相對|會更|更加).*(保險|保障|風險|危險)+.*


      - entities-P:
        - 試試,枯燥,直接去,偷偷,放空,挑戰性,眼界,放手一搏,心動,就來不及,趁,死腦筋,無趣,無聊,呆板,耍廢,新鮮感,見見世面,看看,衝一波,放手一試
        - (不放過|不錯過)+.*(機會|可能性)+,避免.*遺憾,(能|可以|將會)+.*(學到|了解)+,(萌生|產生)+.*(念頭|想法)+
        - (換|改變|跳|轉).*(跑道|工作|機會|職位|領域|未來)+.*


"""

"""###### 模型 v3



```
              precision    recall  f1-score   support

           0       0.79      0.64      0.71       300
           1       0.75      0.72      0.74       272
           2       0.70      0.72      0.71       272
           3       0.82      0.57      0.67       305

   micro avg       0.76      0.66      0.71      1149
   macro avg       0.76      0.66      0.71      1149
weighted avg       0.77      0.66      0.71      1149
 samples avg       0.72      0.64      0.64      1149
 ```


"""

document ="""
config:
    - type: nlu
    - label: mbti


intents:
    - intent1: 
      - entities-E:
        - 同事,上司,主管,老闆,朋友,同學,夥伴,(其他|其它)+.*(人|員工)+
        - 珠寶,手飾,補教業,人事,任用,招募,生涯
        - 行銷,電話,客戶,他們,錄取,人資,員工,管理,加班,部門,人員,助理,朋友,新人,老闆

        - 融入,邊緣,距離感,交流,相處,共事,照顧,態度,口氣,話題,聊得來,社交,尷尬,禮貌,信任,排擠,風氣,相處,起衝突,妥協,難交代,疏遠,疏離
        - (暗自|私底下|私下)+.*(找|和|與|叫|喊)+.*(溝通|協調|合作)+
        - 找不到人問,怎麼回答
        - (一起|大家)+.*(溝通|協調|合作|上班|下班|聊天|吃飯|休息|喝水|裝水|做事)+
      
      
      - entities-I:
        - 成長,學習,閱讀,技能,向上,思考,個人
        - 積極,應徵,機構,念書,主修,國考,穩定,朝九晚五,留學,升遷
        - 會計,分析,資料,導體,半導體,接觸,負責,產品,實習,設備,事務所,專案,現職,身體,加班,科技業,自己個性,自己單位
        - (自己|我|自身)+.*(個性|性格|習慣|經驗|能力|摸索)+
        - 適合.*(自己|我|自身)+
        - 自己來,份內,干擾,隱私,私事,埋頭,鑽牛角尖,專注,不自在,沉默,精進,致力,自我要求,自責,自認,本身,給自己,想清楚,內傷,想通
        - (朝|向)+.*(方面|未來|方向|規劃|計畫)+.*(努力|學習|成長|調整)+
        - 深深.*(覺得|認為)+



    - intent2: 
      - entities-N:
        - 概念,經驗,印象,以前,曾經
        - 剛好,期間,終於,積極,專心,焦慮,萬一,印象,玻璃心,朝九晚五,出國,留學
        - 一邊,總是,結果,外商,喜歡,願意,當時,實際
        - 總覺得,似乎,算是,一想到,不知不覺,很怕之後,難道,大方向,感受到,好像都,難道,大方向,感受到
        - 一想到,不知不覺,很怕.*之後
        - (好像|似乎|大部分|幾乎)+.*(都|全部)+
        - 有.*(感覺|感受)+

      - entities-S:
        - 數據,機率,可能性,推估,業績,金額
        - 偏向,因此,連結,薪資,績效,賺點
        - 資料,分析,研究,業績
        - 何必,尤其,看來,觀察,基於,舉例,後發現,一步一步,合理,再加上



    - intent3: 
      - entities-T:
        - 思考,數據,機率,可能性,推估,估計,業績,成果,成績,學歷,經歷,學校
        - 苦尋,任期,正在,方面,爭取,很想,再次,計算,給予,常性,查詢,工資,許多,勞動,固定,平均,合同,執行,作業,列為,必須,納入,獎金,績效,營收,工資,歷年,這樣,工資,算進,我查,絕對,說法,法務,倒底,判例,恩惠,困惑,解答,法令,比如
        - 助理,遊戲,薪資,設計,工地,管理,也是,同事,內容,履歷,老闆,工程師,退伍,建築,主管,操作,現場,行銷,代理,轉職,未來,如果,學歷,無法,人員,後來,喜歡,一年,問題,是否,發展,可能,最近,時間,什麼,對於,研發,編輯,公職,化學,遇到,這樣,但是,領域,找到,每天,工程
        - 可行,看好,有助於,角度,做打算,長久之計,頂多,偏向於
        - 前途,生涯
        - (比較|相較)+.*有機會


      - entities-F:
        - 感覺,感受,積極,向上,徬徨,積極,動力,喜歡,習慣,興趣,喜好,熱情
        - 近且,鮮少,念書,主修,研究所,符合,考國考,國考,改兼職,壞處,玻璃心,出國,留學,逐漸,動力,有升遷,經無法,週一到,還選擇,台灣會,外派,玩命,回去,還沒,回台灣,口罩,一堆,疫苗,拿命,愛怎樣,確診,聽膩,無感,在連,接種,擠地,超像,之戰,旁邊,不戴,超近,連結,從頭,戴滿,賺點,問現,我調,在衝,再撐
        - 一邊,會計,客戶,英文,採購,護理,加班,維修,美髮,食品,分析,資料,電話,事務,程式,開發,新人,業績,協助,銀行,下班,實習,設備,經理,有時,工廠,門市,事務所,員工,一天,活動,小孩,金融,離開,產品,研究,研發,後來,請假,行銷,媒體,診所,感謝,思考,能夠,一次,決定,不過,私立,起來
        - 心軟,人情,面子,同情,心累,共識,吞下去,的立場,罪惡感,有意義
        - 硬著頭皮.*(答應|完成|成交)+


    - intent4: 
      - entities-J:
        - 居安思危,作業員,焦慮症,憂鬱症,強迫症,重返校園,碩士,研究所,被動收入,安穩,冒險,風險,證照,準時,生活品質,休息,學歷,履歷,行政助理,停損點,空白,加班費,任勞任怨,穩定,固定,輕鬆,生活水準,落榜,公股銀行,空窗,規律,公務,不喜,自傳,安逸,資遣,硬實力,檢定,勞動合約,勞動合同,年終,報加班,公部門,勞基法,國營事業,公職,鐵飯碗,民法,routine,資歷,公務員,安全牌,石沉大海,忐忑,找不到工作
        - 安全,放棄,如期,備案,穩定,長久之計,做打算,想清楚,不確定性,養活,以防,以防萬一,妥善,後路
        - (有|曾).*(想過|計畫|規劃|打算)+.*(但|可是)+,(讓|使)+.*(安心|放心)+
        - (比較|相對|會更|更加).*(保險|保障|風險|危險)+.*


      - entities-P:
        - 成長,限制,廣闊,發展,騎驢找馬,挑戰,嘗試,跨領域,做看看,做做看,夢想,財富自由,創業,升遷,機會,創業,進修,精進,停滯,倦怠,成就感,大事,往上,爬升,身兼,衝勁,從零,徬徨,競爭力,充實自己,跳脫,國際視野,提升自己,枯燥,乏味,探索,資源,闖一闖,爭取,熱情,茫然,體制僵化,放手一搏,專業能力,制式,價值感,價值,衝動,進修,裸辭,自由度,熱忱,危機意識

        - 試試,枯燥,直接去,偷偷,放空,挑戰性,眼界,放手一搏,心動,就來不及,趁,死腦筋,無趣,無聊,呆板,耍廢,新鮮感,見見世面,看看,衝一波,放手一試
        - (不放過|不錯過)+.*(機會|可能性)+,避免.*遺憾,(能|可以|將會)+.*(學到|了解)+,(萌生|產生)+.*(念頭|想法)+
        - (換|改變|跳|轉).*(跑道|工作|機會|職位|領域|未來)+.*



"""

"""###### 模型 v2



```
              precision    recall  f1-score   support

           0       0.79      0.58      0.67       315
           1       0.33      0.72      0.45       109
           2       0.04      0.50      0.08        22
           3       0.79      0.67      0.72       316

   micro avg       0.49      0.63      0.55       762
   macro avg       0.49      0.62      0.48       762
weighted avg       0.70      0.63      0.64       762
 samples avg       0.46      0.56      0.48       762
 ```


"""

document ="""
config:
    - type: nlu
    - label: mbti


intents:
    - intent1: 
      - entities-E:
        - 融入,邊緣,距離感,交流,相處,共事,照顧,態度,口氣,話題,聊得來,社交,尷尬,禮貌,信任,排擠,風氣,相處,起衝突,妥協,難交代,疏遠,疏離
        - (暗自|私底下|私下)+.*(找|和|與|叫|喊)+.*(溝通|協調|合作)+
        - 找不到人問,怎麼回答
        - (一起|大家)+.*(溝通|協調|合作|上班|下班|聊天|吃飯|休息|喝水|裝水|做事)+
      
      
      - entities-I:
        - (自己|我|自身)+.*(個性|性格|習慣|經驗|能力|摸索)+
        - 適合.*(自己|我|自身)+
        - 自己來,份內,干擾,隱私,私事,埋頭,鑽牛角尖,專注,不自在,沉默,精進,致力,自我要求,自責,自認,本身,給自己,想清楚,內傷,想通
        - (朝|向)+.*(方面|未來|方向|規劃|計畫)+.*(努力|學習|成長|調整)+
        - 深深.*(覺得|認為)+



    - intent2: 
      - entities-N:
        - 總覺得,似乎,算是,一想到,不知不覺,很怕之後,難道,大方向,感受到,好像都,難道,大方向,感受到
        - 一想到,不知不覺,很怕.*之後
        - (好像|似乎|大部分|幾乎)+.*(都|全部)+
        - 有.*(感覺|感受)+

      - entities-S:
        - 何必,尤其,看來,觀察,基於,舉例,後發現,一步一步,合理,再加上



    - intent3: 
      - entities-T:
        - 可行,看好,有助於,角度,做打算,長久之計,頂多,偏向於
        - 前途,生涯
        - (比較|相較)+.*有機會


      - entities-F:
        - 心軟,人情,面子,同情,心累,共識,吞下去,的立場,罪惡感,有意義
        - 硬著頭皮.*(答應|完成|成交)+


    - intent4: 
      - entities-J:
        - 安全,放棄,如期,備案,穩定,長久之計,做打算,想清楚,不確定性,養活,以防,以防萬一,妥善,後路
        - (有|曾).*(想過|計畫|規劃|打算)+.*(但|可是)+,(讓|使)+.*(安心|放心)+
        - (比較|相對|會更|更加).*(保險|保障|風險|危險)+.*


      - entities-P:
        - 試試,枯燥,直接去,偷偷,放空,挑戰性,眼界,放手一搏,心動,就來不及,趁,死腦筋,無趣,無聊,呆板,耍廢,新鮮感,見見世面,看看,衝一波,放手一試
        - (不放過|不錯過)+.*(機會|可能性)+,避免.*遺憾,(能|可以|將會)+.*(學到|了解)+,(萌生|產生)+.*(念頭|想法)+
        - (換|改變|跳|轉).*(跑道|工作|機會|職位|領域|未來)+.*


"""

"""###### 模型 v1



```
              precision    recall  f1-score   support

           0       0.72      0.66      0.69       280
           1       0.72      0.63      0.67       270
           2       0.65      0.67      0.66       250
           3       0.68      0.63      0.66       245

   micro avg       0.69      0.65      0.67      1045
   macro avg       0.69      0.65      0.67      1045
weighted avg       0.69      0.65      0.67      1045
 samples avg       0.63      0.61      0.59      1045
 ```


"""

document ="""
config:
    - type: nlu
    - label: mbti


intents:
    - intent1: 
      - entities-E:
        - 同事,上司,主管,老闆,朋友,同學,其他人
        - 珠寶手,補教業,營建業,人事行政,跑道,外商,薪酬,任用,招募,生涯,本土,教育,如果,還沒,我現,回台灣,口罩,每天,一堆,疫苗,國外,身邊,失業,拿命,這裡,規定,愛怎樣,怎樣,確診,聽膩,無感,在連,接種,擠地,超像,之戰,旁邊,不戴,超近,連結,幾乎,從頭,戴滿,賺點,問現,我調,在衝,會不會,太衝動,再撐
        - 行銷,電話,客戶,產品,網頁,開發,設計,品線,產品線,後來,他們,錄取,發展,企劃,餐飲,人資,員工,負責,非常,學習,管理,加班,部門,好像,下班,請假,薪資,職缺,人員,結果,助理,其他,事情,任職,朋友,升遷,平面,新人,相關,國外,老闆,電腦,工程,方面,也是,從事,選擇,第一,這份
      
      - entities-I:
        - 自我成長,技能學習,離職,轉職,閱讀,技能,向上
        - 敘薪,會發,調整,緊換,曾經,修過,但出,社會後因,緣際會,百貨業,期因,剛好,往辦,月後現,終於,專員,很積,極且,Dear,Givers,勞資,往人資,應徵上,機構,因離家,近且,鮮少,念書,主修,符合,考國考,國考,改兼職,壞處,玻璃心,朝九晚五,32,出國,留學,逐漸,動力,有升遷,經無法,週一到,當初,還選擇,台灣會,太衝動,玩命,回去
        - 採購,護理,一邊,客戶,程式,會計,英文,銀行,食品,小孩,遊戲,美髮,編輯,部門,診所,企劃,通知,不錯,開發,分析,資料,導體,半導體,接觸,負責,產品,一點,實習,最後,這些,事務,能夠,一樣,設備,事務所,專案,福利,這份,現職,身體,加班,科技業,外商,個性,單位,研究所,老師,研發,醫院,行業

    - intent2: 
      - entities-N:
        - 概念,經驗,印象,以前,曾經
        - 百貨業,期因,剛好,往辦,期間,月後現,終於,專員,很積,極且,會不會,Dear,Givers,勞資,往人資,專心,焦慮,應徵上,國家,機構,因離家,近且,鮮少,念書,主修,符合,收入,國考,狀況,兼職,改兼職,壞處,萬一,影響,上班,考上,身心,印象,玻璃心,朝九晚五,32,出國,留學,逐漸,動力,有升遷,經無法,負擔,週一到,發生
        - 加班,產品,英文,採購,會計,事務所,一邊,工程師,助理,職缺,銀行,設計,工程,結果,部門,軟體,事務,金融,經理,回答,客戶,不錯,老師,行業,能力,外商,飯店,薪水,喜歡,行銷,願意,完成,正職,下班,財務,當時,業績,產業,實際,三年,餐飲,人資,員工,後來,處理,錄取,關係,服務,不好,企劃

      - entities-S:
        - 數據,機率,可能性,推估,業績,金額
        - 因當時,近尾聲,換人,傳遞,太多應,給他,輕微,語氣,用詞,問很難,有算,入耳,不忙,打雜活,可學習,徵人資,偏向,因此,緊換,考國考,還選擇,台灣會,玩命,回去,還沒,口罩,一堆,疫苗,國外,拿命,愛怎樣,確診,聽膩,無感,在連,接種,擠地,超像,之戰,旁邊,不戴,超近,連結,從頭,戴滿,賺點,問現,我調,在衝,再撐
        - 護理,加班,美髮,活動,開發,企劃,客戶,餐飲,資料,行銷,實習,英文,員工,分析,單位,食品,國外,程式,新人,人資,設備,銀行,產品,門市,網頁,研究,業績,小時,部門,操作,維修,一邊,美容,法律,銷售,診所,製程,編輯,遊戲,在職,努力,這種,結果,投遞,過去,看到,朋友,能夠,原本,有沒有

    - intent3: 
      - entities-T:
        - 思考,數據,機率,可能性,推估,估計,業績,成果,成績,學歷,經歷,學校
        - 但苦,尋不著,我該,任期,似的,正在,方面,爭取,很想,再次,計算,給予,常性,查詢,工資,許多,勞動,固定,平均,合同,執行,作業,列為,必須,納入,終獎,金有,二種,性給予,績效,營收,而經,工資內,我現,我們,歷年,這樣子,工資時,算進,我查,絕對,說法,法務,倒底,判例,恩惠,困惑,解答,法令,比如
        - 助理,遊戲,薪資,設計,工地,管理,一份,也是,同事,內容,履歷,個月,老闆,工程師,退伍,建築,主管,操作,現場,行銷,代理,轉職,未來,如果,學歷,無法,人員,後來,喜歡,一年,問題,是否,發展,可能,最近,時間,什麼,對於,研發,編輯,公職,化學,遇到,這樣,但是,領域,找到,這個,每天,工程

      - entities-F:
        - 感覺,感受,積極,向上,徬徨,積極,動力,喜歡,習慣,興趣,喜好,熱情
        - 近且,鮮少,念書,主修,研究所,符合,考國考,國考,改兼職,壞處,玻璃心,32,出國,留學,逐漸,動力,有升遷,經無法,週一到,還選擇,台灣會,外派,玩命,回去,還沒,回台灣,口罩,一堆,疫苗,拿命,愛怎樣,確診,聽膩,無感,在連,接種,擠地,超像,之戰,旁邊,不戴,超近,連結,從頭,戴滿,賺點,問現,我調,在衝,再撐
        - 一邊,會計,客戶,英文,採購,護理,加班,維修,美髮,食品,分析,資料,電話,事務,程式,開發,新人,業績,協助,銀行,下班,實習,設備,經理,有時,工廠,門市,事務所,員工,一天,活動,小孩,金融,離開,產品,研究,研發,後來,請假,行銷,媒體,診所,感謝,思考,能夠,一次,決定,不過,私立,起來

    - intent4: 
      - entities-J:
        - 居安思危,作業員,焦慮症,憂鬱症,強迫症,重返校園,碩士,研究所,被動收入,安安穩穩,冒險,風險,證照,準時,生活品質,休息,學歷,履歷,行政助理,停損點,空白,加班費,任勞任怨,穩定,固定,輕鬆,生活水準,落榜,公股銀行,空窗,規律,公務,不喜,自傳,安逸,資遣,硬實力,檢定,勞動合約,勞動合同,年終,報加班,公部門,勞基法,國營事業,公職,鐵飯碗,民法,routine,資歷,公務員,安全牌,石沉大海,忐忑,找不到工作
        - 護理,會計,英文,採購,加班,美髮,經理,食品,結果,餐飲,設計,事務所,客戶,醫院,產品,系統,專案,下班,電話,行業,確定,技術,回答,銀行,人資,員工,程式,門市,事務,操作,新人,訓練,離開,行銷,行政,專業,網頁,實習,維修,美容,銷售,診所,一邊,事情,部門,小孩,禮拜,研發,製程,不能
        - 安全,放棄,如期,備案,穩定,長久之計,長久,打算,想清楚,不確定,比較保險,養活,以防,以防萬一,妥善
        - 有想過..但..	讓...安心

      - entities-P:
        - 成長,有限,廣闊,職涯發展,騎驢找馬,挑戰,嘗試,跨領域,做看看,做做看,夢想,財富自由,創業,升遷,機會,轉換跑道,換跑道,創業,進修,精進,停滯,倦怠,成就感,大事,往上,爬升,身兼,衝勁,從零,徬徨,競爭力,充實自己,跳脫,國際視野,提升自己,枯燥,乏味,探索,資源,闖一闖,爭取,熱情,茫然,體制僵化,放手一搏,專業能力,制式,價值感,價值,衝動,進修,裸辭,自由度,熱忱,危機意識
        - 近且,鮮少,念書,主修,研究所,符合,考國考,國考,改兼職,壞處,玻璃心,32,出國,留學,逐漸,動力,有升遷,經無法,週一到,還選擇,台灣會,外派,玩命,回去,還沒,回台灣,口罩,一堆,疫苗,拿命,愛怎樣,確診,聽膩,無感,在連,接種,擠地,超像,之戰,旁邊,不戴,超近,連結,從頭,戴滿,賺點,問現,我調,在衝,再撐
        - 銀行,行銷,產品,企劃,工程,證照,台灣,單位,工程師,客戶,英文,國外,開發,資料,通知,加班,研究,分析,實習,編輯,業績,法律,金融,設計,活動,越來越,領域,程式,他們,要求,甚至,完全,嘗試,不太,努力,本身,科技,穩定,也不,部分,期間,科系,準備,請教,遇到,不同,當初,一點,也沒,直接

      
"""

"""# 上傳"""

stop

# !rm -rf MBTI-ckiplab-bert
!apt install git-lfs

from huggingface_hub import notebook_login
notebook_login()

!rm -rf uploadModel
!mkdir uploadModel
!cp -r ./results/checkpoint-1000/* ./uploadModel/

upload_model = AutoModelForSequenceClassification.from_pretrained("./uploadModel/")
#
path = "sentcore"
training_args.output_dir="MBTI-ckiplab-bert"
training_args.push_to_hub=True
training_args.overwrite_output_dir=True

#
upload_trainer = Trainer(model=upload_model,args=training_args)

upload_trainer.push_to_hub(
    commit_message="v1.0.2 best_threshold: 0.411",
    tags=["MBTI","zh","zh-tw"],
    tasks=["Text Classification"],
    language=["zh"]
)

"""#接口測試"""

from transformers import AutoModelForSequenceClassification
from transformers import BertTokenizerFast
# tokenizer = BertTokenizer.from_pretrained(bert_model)
tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')
online_model = AutoModelForSequenceClassification.from_pretrained(
    "theta/MBTI-ckiplab-bert",
    # revision="a02297f",
    output_attentions=True,
    use_auth_token="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")
title = "我畢業於致理科技大學，曾待過位於101的日商公司，目前也待在美商公司中，雖擔任的是行銷總監職務卻已經包辦公司大小事，幾乎除業務以外我都有負責，我和業務主管可以說是公司的二把手 然而最近兩年卻發生海外部門主管捲款、工程師部門把案子做壞、遊戲部門把公司案子私底下偷偷承接等事情，搞的公司已經沒錢了，我也只好趁這時候轉職，原以為38歲主管經驗OK的我應該可以很快找到工作，但很奇妙的是不管台商外商投了履歷後都是無聲卡，  在三年前在日本出差時投日本履歷接到一堆面試跟現在投日商(包含日商仲介)相比，現在一堆無聲卡真的很讓人納悶，連個回應都沒有，我甚至在想是不是年紀問題一類，若不是年紀的話又是怎麼回事?"

"""pipeline"""

import numpy as np
import re
from transformers import Pipeline
from transformers.utils import ExplicitEnum, add_end_docstrings, is_tf_available, is_torch_available
from typing import Union, List, Dict
if is_tf_available():
    from transformers.models.auto.modeling_tf_auto import TF_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING
if is_torch_available():
    from transformers.models.auto.modeling_auto import MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING



class ClassificationFunction(ExplicitEnum):
    SIGMOID = "sigmoid"
    SOFTMAX = "softmax"
    NONE = "none"

def sigmoid(_outputs):
    return 1.0 / (1.0 + np.exp(-_outputs))

def softmax(_outputs):
    maxes = np.max(_outputs, axis=-1, keepdims=True)
    shifted_exp = np.exp(_outputs - maxes)
    return shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)

class MultiClassificationPipeline(Pipeline):
    """
    Text classification pipeline using any `ModelForSequenceClassification`. See the [sequence classification
    examples](../task_summary#sequence-classification) for more information.
    This text classification pipeline can currently be loaded from [`pipeline`] using the following task identifier:
    `"sentiment-analysis"` (for classifying sequences according to positive or negative sentiments).
    If multiple classification labels are available (`model.config.num_labels >= 2`), the pipeline will run a softmax
    over the results. If there is a single label, the pipeline will run a sigmoid over the result.
    The models that this pipeline can use are models that have been fine-tuned on a sequence classification task. See
    the up-to-date list of available models on
    [huggingface.co/models](https://huggingface.co/models?filter=text-classification).
    """

    return_all_scores = False
    function_to_apply = ClassificationFunction.NONE

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        self.check_model_type(
            TF_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING
            if self.framework == "tf"
            else MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING
        )

        self.tokenizer_inputs = None
    def keep_zh(self, text):
      return re.sub(r'[^\u4e00-\u9fa5]','',text)
    def _sanitize_parameters(self, return_all_scores=None, function_to_apply=None, **tokenizer_kwargs):
        preprocess_params = tokenizer_kwargs

        postprocess_params = {}
        if hasattr(self.model.config, "return_all_scores") and return_all_scores is None:
            return_all_scores = self.model.config.return_all_scores

        if return_all_scores is not None:
            postprocess_params["return_all_scores"] = return_all_scores

        if isinstance(function_to_apply, str):
            function_to_apply = ClassificationFunction[function_to_apply.upper()]

        if function_to_apply is not None:
            postprocess_params["function_to_apply"] = function_to_apply
        return preprocess_params, {}, postprocess_params

    def __call__(self, *args, **kwargs):
        """
        Classify the text(s) given as inputs.
        Args:
            args (`str` or `List[str]`):
                One or several texts (or one list of prompts) to classify.
            return_all_scores (`bool`, *optional*, defaults to `False`):
                Whether to return scores for all labels.
            function_to_apply (`str`, *optional*, defaults to `"default"`):
                The function to apply to the model outputs in order to retrieve the scores. Accepts four different
                values:
                If this argument is not specified, then it will apply the following functions according to the number
                of labels:
                - If the model has a single label, will apply the sigmoid function on the output.
                - If the model has several labels, will apply the softmax function on the output.
                Possible values are:
                - `"sigmoid"`: Applies the sigmoid function on the output.
                - `"softmax"`: Applies the softmax function on the output.
                - `"none"`: Does not apply any function on the output.
        Return:
            A list or a list of list of `dict`: Each result comes as list of dictionaries with the following keys:
            - **label** (`str`) -- The label predicted.
            - **score** (`float`) -- The corresponding probability.
            If `self.return_all_scores=True`, one such dictionary is returned per label.
        """
        result = super().__call__(*args, **kwargs)
        if isinstance(args[0], str):
            # This pipeline is odd, and return a list when single item is run
            return [result]
        else:
            return result

    def preprocess(self, inputs, **tokenizer_kwargs) -> Dict[str, Union[List["GenericTensor"], "torch.Tensor", "tf.Tensor"]]:
        # print(inputs)
        inputs = self.keep_zh(inputs)
        return_tensors = self.framework
        tokenizer_inputs = self.tokenizer(inputs, return_tensors=return_tensors, **tokenizer_kwargs)
        # self.tokenizer_inputs = self.tokenizer.convert_ids_to_tokens(tokenizer_inputs['input_ids'][0])
        return tokenizer_inputs

    def _forward(self, model_inputs):
        result = self.model(**model_inputs)
        return result

    def postprocess(self, model_outputs, function_to_apply=None, return_all_scores=False):
        # Default value before `set_parameters`
        if function_to_apply is None:
            if self.model.config.problem_type == "multi_label_classification" or self.model.config.num_labels == 1:
                function_to_apply = ClassificationFunction.SIGMOID
            elif self.model.config.problem_type == "single_label_classification" or self.model.config.num_labels > 1:
                function_to_apply = ClassificationFunction.SOFTMAX
            elif hasattr(self.model.config, "function_to_apply") and function_to_apply is None:
                function_to_apply = self.model.config.function_to_apply
            else:
                function_to_apply = ClassificationFunction.NONE

        outputs = model_outputs["logits"][0]
        attention = [0,0]#[round(vec,5) for vec in self.attention2value(model_outputs["attentions"])]
        outputs = outputs.numpy()

        if function_to_apply == ClassificationFunction.SIGMOID:
            scores = sigmoid(outputs)
        elif function_to_apply == ClassificationFunction.SOFTMAX:
            scores = softmax(outputs)
        elif function_to_apply == ClassificationFunction.NONE:
            scores = outputs
        else:
            raise ValueError(f"Unrecognized `function_to_apply` argument: {function_to_apply}")

        if return_all_scores:
            return {
                "labels": [{"label": self.model.config.id2label[i], "score": score.item()} for i, score in enumerate(scores)],
                "content": self.tokenizer_inputs,
                "attention": attention,
                # "length":len(self.tokenizer_inputs)
            }
            
        else:
            return [score.item() for i, score in enumerate(scores)]

    def attention2value(self, attention):
        def level_attention_value(arr_2d):
          attention_base = arr_2d[0].numpy()
          for unit in arr_2d[1:]:
            attention_base+=unit.numpy()
          return attention_base
        attention_base, level_count = np.array([0.0]*len(self.tokenizer_inputs)), 0
        for level1 in attention:
          for level2 in level1[0]:
            level_count+=1
            attention_base += level_attention_value(level2)
        return attention_base/level_count

import datetime

#
PipelineInterface = MultiClassificationPipeline(model=online_model, tokenizer=tokenizer, return_all_scores=True,batch_size=1)

s = datetime.datetime.now()
print(PipelineInterface([
    "同理心很重要",
    "自然公園可以去做",
    "先把握當下珍惜眼前",
    "在善良之餘設定底線",
    "可以找其他兼職補貼",
    "也許這個只是你的設想"
  ]))

#
print(f"總時間: {(datetime.datetime.now() - s).microseconds/1000000}s")
